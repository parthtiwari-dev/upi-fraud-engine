# ğŸš¨ Real-Time UPI Fraud Detection System

> A production-grade, end-to-end machine learning system that simulates real-world fintech fraud detection â€” from raw data generation to live deployment with strict temporal correctness, alert budgets, and business metrics.

---

## ğŸŒ What This Project Actually Is (Not Just Another ML Model)

Most ML projects stop at:
> dataset â†’ model â†’ accuracy â†’ done

This project simulates a **real fintech fraud detection system**, including:

- realistic UPI transaction generation
- ingestion pipelines (batch + streaming)
- data validation & leakage prevention
- point-in-time feature engineering
- two-stage fraud modeling
- A/B testing & backtesting
- alert budget & business metrics
- real-time API + UI deployment

This is closer to how Stripe / Paytm / PhonePe systems work than Kaggle notebooks.

---

## ğŸ§  System Architecture (High-Level)

```
USER / CLIENT
    â”‚
    â–¼
Streamlit UI (Frontend)
    â”‚
    â–¼
FastAPI Backend (Dockerized)
    â”‚
    â–¼
Online Feature Store (Stateful)
    â”‚
    â–¼
Two-Stage Fraud Model (Isolation Forest + XGBoost)
    â”‚
    â–¼
Alert Policy Engine (0.5% Budget)
    â”‚
    â–¼
Fraud Decision + Business Metrics
```

---

## ğŸ—ï¸ End-to-End Pipeline Architecture

```
PHASE 1 â”€ Data Generation
    â†“
PHASE 2 â”€ Ingestion (Batch + Streaming)
    â†“
PHASE 3 â”€ Data Validation (Great Expectations)
    â†“
PHASE 4 â”€ Feature Engineering (Point-in-Time Safe)
    â†“
PHASE 5 â”€ Model Training & Leakage Audit
    â†“
PHASE 6 â”€ Backtesting & Business Evaluation
    â†“
PHASE 7 â”€ Real-Time Fraud API
    â†“
PHASE 8 â”€ Production Deployment
```

---

# ğŸ“Š Key Results

### Dataset
- Total transactions: **1,097,231**
- Fraud rate: **3.6% (labeled data)**
- Features: **482 production-safe features**

### Model Performance
- ROC-AUC: **0.8918** (leakage-free)
- Precision @ 0.5% alert budget: **~92%**
- Recall @ 0.5% alert budget: **~12%**

### Production Metrics
- Latency: **~233ms avg (<500ms target)**
- Deployment: Render + Streamlit Cloud
- Architecture: Docker + FastAPI + Stateful Features

---

# ğŸ§© Phase-by-Phase Breakdown

---

## PHASE 1 â€” Realistic UPI Data Generation

### Goal
Simulate a real UPI transaction ecosystem with fraud patterns.

### Key Features
- Device rings
- Velocity spikes
- Time anomalies
- Label delays (realistic fraud discovery)

### Output
- DuckDB database with 1.1M+ transactions

```
RAW DATA â†’ UPI SCHEMA â†’ FRAUD INJECTION â†’ VALIDATION â†’ DUCKDB
```

---

## PHASE 2 â€” Ingestion Pipeline (Batch + Streaming)

### Problem Solved
Training-serving skew (the #1 ML production bug).

### Architecture
```
DuckDB
  â”œâ”€ Batch Loader (Training)
  â””â”€ Streaming Simulator (Serving)
         â†“
   Consistency Check (100% match)
```

### Result
- Guaranteed identical data formats across offline & online paths.

---

## PHASE 3 â€” Data Validation & Leakage Prevention

### Tools
- Great Expectations

### Rules Enforced
- schema correctness
- type safety
- unique IDs
- temporal causality
- label delay constraints

### Key Insight
> No model can be trusted if the data is not causally correct.

---

## PHASE 4 â€” Feature Engineering (Point-in-Time Safe)

### Feature Families
1. Velocity features (5min, 1h, 24h)
2. Graph features (device â†” users)
3. Risk history (label-aware)

### Core Principle
For every transaction T:
> features must only use data from time < T

### Output
- 487 total features
- zero future leakage

---

## PHASE 5 â€” Model Training & Leakage Audit

### Two-Stage Architecture

```
Stage 1: Isolation Forest (Anomaly Detection)
Stage 2: XGBoost (Fraud Classification)
```

### Critical Discovery
Synthetic column `fraud_pattern` caused label leakage.

```
AUC with leakage: 0.9106
AUC without leakage: 0.8918
```

### Decision
Deploy leakage-free model despite lower metrics.

---

## PHASE 6 â€” Backtesting & Business Evaluation

### Why Normal ML Metrics Are Not Enough
Real systems operate under constraints.

### Implemented
- day-by-day replay
- alert budget enforcement (0.5%)
- cost-benefit analysis
- ROI estimation

### Example Result
```
Daily savings â‰ˆ â‚¹6,00,000
Annual ROI â‰ˆ 7400%
```

---

## PHASE 7 â€” Real-Time Fraud Detection API

### Architecture

```
FastAPI API
   â†“
Online Feature Store (stateful)
   â†“
XGBoost Model
   â†“
Alert Policy Engine
```

### Key Capabilities
- real-time scoring (<500ms)
- stateful feature updates
- alert budget logic
- business-layer decision making

---

## PHASE 8 â€” Production Deployment

### Stack
- Backend: FastAPI + Docker + Render
- Frontend: Streamlit Cloud

### Live System Flow

```
User â†’ Streamlit UI â†’ FastAPI API â†’ Model â†’ Decision
```

---

# ğŸ§± Repository Structure

```
upi-fraud-engine/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/            # FastAPI backend
â”‚   â”œâ”€â”€ ingestion/      # Batch & streaming loaders
â”‚   â”œâ”€â”€ validation/     # Great Expectations
â”‚   â”œâ”€â”€ features/       # Feature engineering
â”‚   â”œâ”€â”€ evaluation/     # Backtesting & metrics
â”‚   â””â”€â”€ inference/      # Model inference
â”œâ”€â”€ models/             # Trained models & encoders
â”œâ”€â”€ data_generation/    # Synthetic UPI data pipeline
â”œâ”€â”€ evaluation/         # Reports & visualizations
â”œâ”€â”€ docs/               # Phase-wise documentation
â”œâ”€â”€ notebooks/          # Experiments
â”œâ”€â”€ dockerfile          # Deployment
â”œâ”€â”€ app.py              # Streamlit UI
â””â”€â”€ README.md           # (this file)
```

---

# ğŸ¯ Core Design Principles

### 1) Temporal Correctness
No future information is used in training or inference.

### 2) Trainingâ€“Serving Parity
Batch and streaming pipelines are identical.

### 3) Business-First Evaluation
Metrics reflect operational constraints, not just accuracy.

### 4) Production Realism
System designed like a fintech fraud engine, not a Kaggle project.

---

# ğŸš€ Why This Project Matters

This project demonstrates:

- ML system design, not just modeling
- data engineering + ML + backend integration
- real-world fraud detection constraints
- production deployment skills

It bridges the gap between:

> "I trained a model" â†’ "I built a real ML system"

---

# ğŸ§­ Future Work

- Kafka-based real streaming
- Redis-backed feature store
- model retraining pipeline
- drift detection & monitoring
- online A/B testing
- real UPI-like datasets

---

# ğŸ‘¤ Author

**Parth Tiwari**

Aspiring ML / AI Engineer focused on building production-grade ML systems.

---

# ğŸ§  If You Read This Far

This repository is not about maximizing accuracy.

It is about answering a harder question:

> "What does it actually take to build a real fraud detection system?"

